{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "qwmb7yHYl8xC",
        "_Qb-9JfNl-H6",
        "oRTpdQu2l_zc",
        "J3MvZQIqmBNC",
        "19v4C3CymCD7",
        "Y0ujt68NmCvq",
        "UbdGY7LMmDqq",
        "FIkQrH2XmEkK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **University of Toronto**\n",
        "### Learn to Program: Crafting Quality Code"
      ],
      "metadata": {
        "id": "lCqlbQktpk3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Week 2 - Excercises"
      ],
      "metadata": {
        "id": "kuI7JYNlkjHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1 ✅"
      ],
      "metadata": {
        "id": "qwmb7yHYl8xC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code:\n",
        "```\n",
        "def high_low(guess, actual):\n",
        "    \"\"\" (int, int) -> str\n",
        "\n",
        "    Return \"your guess is low\" if guess is lower than actual,\n",
        "    \"your guess is high\" if guess is higher than actual, and\n",
        "    \"correct\" if guess is equal to actual.\n",
        "\n",
        "    >>> high_low(4, 10)\n",
        "    \"your guess is low\"\n",
        "    \"\"\"\n",
        "```\n",
        "Which set of test cases is the best choice of tests cases for this function? (Think about the Boundaries category for choosing test cases.)\n"
      ],
      "metadata": {
        "id": "yej33X_ekm5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta correta:\n",
        "• guess refers to a value that is less than the value referred to by actual\n",
        "• guess refers to a value equal to the value referred to by actual\n",
        "• guess refers to a value that is greater than the value referred to by actual"
      ],
      "metadata": {
        "id": "LoBvOFRFk1UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2 ✅"
      ],
      "metadata": {
        "id": "_Qb-9JfNl-H6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code:\n",
        "\n",
        "\n",
        "```\n",
        "def first_two_items(L):\n",
        "    \"\"\" (list of str) -> list of str\n",
        "\n",
        "    Return the first two items in L. If there are fewer than\n",
        "    two items in L, return all of the items.\n",
        "\n",
        "    >>> first_two_items([\"apple\", \"pear\", \"grape\"])\n",
        "    [\"apple\", \"pear\"]\n",
        "    \"\"\"\n",
        "```\n",
        "Which of these sets of values for L is the best choice of tests cases for this function?  (Think about the Size category for choosing test cases.)\n"
      ],
      "metadata": {
        "id": "cL-OWyvrmKJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta correta:\n",
        "[]\n",
        "[\"one\"]\n",
        "[\"one\", \"two\"]\n",
        "[\"one\", \"two\", \"three\", \"four\"]"
      ],
      "metadata": {
        "id": "mN4Pops_mQ8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3 ✅"
      ],
      "metadata": {
        "id": "oRTpdQu2l_zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code:\n",
        "\n",
        "```\n",
        "def is_preschooler(age):\n",
        "    \"\"\" (int) -> bool\n",
        "\n",
        "    Precondition: age >= 0\n",
        "\n",
        "    Return True if and only if age is between 3 and 5\n",
        "    inclusive.\n",
        "\n",
        "    >>> is_preschooler(4)\n",
        "    True\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "Which set of test cases is the best choice of tests cases for this function?  (Think about which test case category you might want to consider.)\n",
        "\n"
      ],
      "metadata": {
        "id": "p7xa0-Lmnnkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta Correta\n",
        "# 0 or 1\n",
        "# 2\n",
        "# 3\n",
        "# 4\n",
        "# 5\n",
        "# 6\n",
        "# one number over 6"
      ],
      "metadata": {
        "id": "J4_Il42hnm-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4 ✅"
      ],
      "metadata": {
        "id": "J3MvZQIqmBNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code:\n",
        "\n",
        "```\n",
        "def count_occurrences(s, ch):\n",
        "    \"\"\" (str, str) -> int\n",
        "\n",
        "    Precondition: len(ch) == 1\n",
        "\n",
        "    Return the number of occurrences of ch in s.\n",
        "\n",
        "    >>> count_occurrences(\"hello\", \"l\")\n",
        "    2\n",
        "    \"\"\"\n",
        "```\n",
        "Which of these sets of values for ```s``` and\n",
        "```ch``` is the best choice of tests cases for this function?  (There are several test case categories for this question, including at least Size and Dichotomies.)\n"
      ],
      "metadata": {
        "id": "OfuobwPDtn1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta Correta\n",
        "# s refers to '', ch refers to 'a'\n",
        "# s refers to 'a'ch refers to 'a'\n",
        "# s refers to 'a', ch refers to 'b'\n",
        "# s refers to 'abc', ch refers to 'b'\n",
        "# s refers to 'abc', ch refers to 'd'\n",
        "# s refers to 'abcabca' ch refers to 'a'"
      ],
      "metadata": {
        "id": "VgWmpjX5tpXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 5"
      ],
      "metadata": {
        "id": "19v4C3CymCD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code:\n",
        "\n",
        "\n",
        "```\n",
        "def can_vote(age):\n",
        "    \"\"\" (int) -> bool\n",
        "\n",
        "    Precondition: age >= 0\n",
        "\n",
        "    Return True if and only if a person aged age can vote\n",
        "    in Canada. The legal voting age in Canada is 18 years and\n",
        "    older.\n",
        "    \"\"\"\n",
        "    \n",
        "   return age > 18\n",
        "```\n",
        "There is a bug in the implementation of the function above (the code does not work as described). Select the test(s) that reveal the bug.  (Think about which test case category might help you reveal this bug.)\n",
        "\n"
      ],
      "metadata": {
        "id": "FBjXSBGEuJtU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZXwKS7wuXZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6"
      ],
      "metadata": {
        "id": "Y0ujt68NmCvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code:\n",
        "\n",
        "\n",
        "```\n",
        "def contains_item(L, s):\n",
        "    \"\"\" (list, object) -> bool\n",
        "\n",
        "    Return True if and only if s is an item of L.\n",
        "    \"\"\"\n",
        "\n",
        "    for item in L:\n",
        "        if item == s:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "```\n",
        "\n",
        "There are bugs in the implementation of the function above (the code does not work as described). Select the test(s) that reveal the bugs.   (Think about the Order category for choosing test cases.)"
      ],
      "metadata": {
        "id": "UUFqcerjukbh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gu1Lq48Yuj5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7 ✅"
      ],
      "metadata": {
        "id": "UbdGY7LMmDqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code:\n",
        "\n",
        "\n",
        "```\n",
        "def sum_items(L):\n",
        "    \"\"\" (list of number) -> number\n",
        "  \n",
        "    Return the sum of the items in L.\n",
        "    \"\"\"\n",
        "\n",
        "    total = 0\n",
        "\n",
        "    for item in L:\n",
        "        total = item\n",
        "\n",
        "    return total\n",
        "```\n",
        "\n",
        "There is a bug in the implementation of the function above (the code does not work as described). Select the test(s) that reveal the bug."
      ],
      "metadata": {
        "id": "bk8u45fuu4h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta Correta\n",
        "# L refers to [1, 0, 1]\n",
        "# L refers to [1, 2]"
      ],
      "metadata": {
        "id": "mz2JxYXQu-at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 8 ✅"
      ],
      "metadata": {
        "id": "FIkQrH2XmEkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code:\n",
        "\n",
        "\n",
        "```\n",
        "def can_afford(item_cost, wallet_money):\n",
        "    \"\"\" (float, float) -> bool\n",
        "\n",
        "   Return True if and only if wallet_money is greater or equal\n",
        "   to item_cost.\n",
        "\n",
        "   >>> can_afford(3.42, 10.00)\n",
        "   True\n",
        "   >>> can_afford(27.32, 5.00)\n",
        "   False\n",
        "   \"\"\"\n",
        "```\n",
        "\n",
        "You are implementing a ```unittest``` test class to test ```can_afford```. Which of the following names can be used as the name of one of your test methods?\n",
        "\n"
      ],
      "metadata": {
        "id": "vrP_nquuvISL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta Correta\n",
        "# test_can_afford"
      ],
      "metadata": {
        "id": "NLLaNDjxvWLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 9 ✅"
      ],
      "metadata": {
        "id": "Evx6hVnwmFW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code, which is in a file called ```words.py```\n",
        "\n",
        "```\n",
        "def word_frequency(letter_to_words):\n",
        "    \"\"\" (dict of {str: list of str}) -> dict of {str: int}\n",
        "\n",
        "    Precondition: the length of each list in letter_to_words\n",
        "    is at least 1, each key in letter_to_words is a lowercase\n",
        "    letter, and each value is a list of lowercase words\n",
        "    beginning with that letter.\n",
        "\n",
        "    Return a dictionary where the keys are the letters from\n",
        "    letter_to_words, and the values are the number of words\n",
        "    beginning with that letter in letter_to_words.\n",
        "\n",
        "    >>> d = {'a': ['apple'], 'b': ['beet', 'banana'],\n",
        "       'c': ['carrot', 'cucumber']}\n",
        "    >>> expected = {'a': 1, 'b': 2, 'c': 2}\n",
        "    >>> word_frequency(d) == expected\n",
        "    True\n",
        "    \"\"\"\n",
        "```\n",
        "Consider this ```unittest``` method header:\n",
        "\n",
        "```\n",
        "def test_word_frequency(self):\n",
        "    \"\"\" A dictionary with several items.\"\"\"\n",
        "\n",
        "    # Add body here.\n",
        "```\n",
        "\n",
        "Select the ```unittest``` method body(ies) that are equivalent to the ```doctest``` in the ```word_frequencey``` docstring.  You can assume that ```words``` has been imported.\n",
        "\n"
      ],
      "metadata": {
        "id": "ayU1hye1vZFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta correta\n",
        "# d = {'a': ['apple'], 'b': ['beet', 'banana'], 'c': ['carrot', 'cucumber']}\n",
        "# actual = words.word_frequency(d)\n",
        "# expected = {'a': 1, 'b': 2, 'c': 2}\n",
        "# self.assertEqual(actual, expected)\n",
        "\n",
        "# e\n",
        "\n",
        "# d = {'a': ['apple'], 'b': ['beet', 'banana'], 'c': ['carrot', 'cucumber']}\n",
        "# actual = words.word_frequency(d)\n",
        "# expected = {'c': 2, 'b': 2, 'a': 1}\n",
        "# self.assertEqual(actual, expected)\n"
      ],
      "metadata": {
        "id": "lZVhn5Wbv21M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 10 ✅"
      ],
      "metadata": {
        "id": "R6RlcsDomGF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this code, which is in a file called ```words.py```:\n",
        "\n",
        "```\n",
        "def make_uppercase(L):\n",
        "    \"\"\" (list of str) -> NoneType\n",
        "\n",
        "    Convert all letters in each string in L to uppercase.\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "Consider this ```unittest``` method header:\n",
        "\n",
        "```\n",
        "def test_make_uppercase(self):\n",
        "    \"\"\" A list with several items.\"\"\"\n",
        "\n",
        "    # Add body here.\n",
        "```\n",
        "\n",
        "Select the method body(ies) that correctly test the function with the list\n",
        "```[’Ada Lovelace’, ’Grace Hopper’, ’Alan Turing’]```.   You can assume that  \n",
        "```words``` has been imported."
      ],
      "metadata": {
        "id": "0FdxzZ7Yv638"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta Correta\n",
        "# L = ['Ada Lovelace', 'Grace Hopper', 'Alan Turing']\n",
        "# words.make_uppercase(L)\n",
        "# expected = ['ADA LOVELACE', 'GRACE HOPPER', 'ALAN TURING']\n",
        "# self.assertEqual(L, expected)"
      ],
      "metadata": {
        "id": "1gEV3ivTwQj9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}